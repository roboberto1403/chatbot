import os
import json
from typing import TypedDict, List, Dict, Any
from langgraph.graph import StateGraph, END
from google import genai
from bson import ObjectId
from database.configurations import collection
from database.models import State

# --- CONSTANTES DE CONFIGURA√á√ÉO ---
MODEL_NAME = "gemini-2.5-flash-lite"
EMERGENCY_KEYWORDS = [
    # Cardiovasculares
    "dor no peito", "press√£o no peito", "dor no cora√ß√£o", "taquicardia", "palpita√ß√£o forte",
    
    # Respirat√≥rios
    "falta de ar", "dificuldade para respirar", "respira√ß√£o curta", "chiado no peito", "n√£o consigo respirar", "engasguei",
    
    # Neurol√≥gicos
    "desmaio", "perda de consci√™ncia", "n√£o consigo falar", "fraqueza de um lado do corpo", "formigamento s√∫bito",
    
    # Hemorragia / Trauma
    "sangramento intenso", "sangramento que n√£o para", "muito sangue", "hemorragia", "corte profundo", "acidente grave",
    
    # Outros cr√≠ticos
    "parada cardiaca", "parada respirat√≥ria", "sem pulso", "convuls√£o", "ataque epil√©ptico", "choque el√©trico"
]
# -------------------------------
# 1. Prompt do agente 
# -------------------------------
SYSTEM_PROMPT = f"""
Voc√™ √© o assistente virtual da ClinicAI. Sua miss√£o √© conduzir uma triagem inicial:
1. Comece se apresentando, deixando claro que voc√™ coleta informa√ß√µes para agilizar a consulta e N√ÉO substitui o diagn√≥stico m√©dico.
2. Colete sistematicamente as informa√ß√µes-chave: Queixa Principal, Sintomas Detalhados, Dura√ß√£o/Frequ√™ncia, Intensidade (0-10), Hist√≥rico Relevante e Medidas Tomadas.
3. Ponto de Conclus√£o OBRIGAT√ìRIO: Quando sentir que TODOS os campos em 'triagem_data' est√£o preenchidos, voc√™ DEVE gerar um RESUMO COMPLETO de todas as informa√ß√µes coletadas no campo `next_response` e terminar perguntando ao usu√°rio: "As informa√ß√µes acima est√£o corretas, e podemos encerrar a triagem e salvar os dados?"
4. N√ÉO forne√ßa diagn√≥sticos, tratamentos, nem sugest√µes m√©dicas.

A sua SA√çDA DEVE SER SEMPRE UM OBJETO JSON V√ÅLIDO, contendo APENAS dois campos:
- "next_response": Sua resposta em linguagem natural para o usu√°rio.
- "triagem_data": Um objeto com os dados estruturados da triagem.

O FORMATO JSON OBRIGAT√ìRIO √©:
{{
 "next_response": "Sua pr√≥xima pergunta, ou resumo/pergunta de confirma√ß√£o.",
 "triagem_data": {{
 "queixa_principal":"",
 "sintomas_detalhados":"",
 "duracao_frequencia":"",
 "intensidade":"",
 "historico_relevante":"",
 "medidas_tomadas":"",
 "emergency_alert": false
 }}
}}
Se o usu√°rio mencionou sintomas de emerg√™ncia, defina 'emergency_alert': true.
"""

# -------------------------------
# 2. Inicializa√ß√£o do Cliente
# -------------------------------
llm = genai.Client(api_key=os.getenv("GOOGLE_API_KEY"))

# ----------------------------------------------------
# 3. Fun√ß√µes Auxiliares e Nodos
# ----------------------------------------------------

def clean_json_string(text: str) -> str:
    """Limpa a string de resposta do LLM, removendo wrappers Markdown e texto extra."""
    text = text.strip()
    if text.startswith("```json"):
        text = text[7:]
    if text.endswith("```"):
        text = text[:-3]
    return text.strip()

def chatbot_node(state: State):
    """
    N√≥ principal: Interage, gera resposta, extrai triagem, e atualiza o estado em UMA CHAMADA.
    """
    messages = state.get("messages", [])

    # 1. VERIFICA√á√ÉO DE CONFIRMA√á√ÉO (CHECA A √öLTIMA MENSAGEM DO USU√ÅRIO)
    last_user_input = messages[-1].get("text", "").lower()
    confirmation_keywords = ["sim", "confirmo", "correto", "pode salvar", "pode terminar"]
    user_confirmed_summary = any(kw in last_user_input for kw in confirmation_keywords)
    
    # 2. DECIDE O PROMPT A SER ENVIADO
    forced_instruction = ""
    new_resumo_confirmado = state.get("resumo_confirmado", False) 
    
    if user_confirmed_summary and not new_resumo_confirmado:
        # Se o usu√°rio confirmou e ainda n√£o tinha a flag, a mensagem final √© for√ßada
        forced_instruction = (
            "\n\n INSTRU√á√ÉO DE FLUXO: O usu√°rio CONFIRMOU o resumo na √∫ltima mensagem. "
            "Sua √öNICA TAREFA agora √© gerar a mensagem final para o usu√°rio no 'next_response': "
            "'√ìtimo! Sua triagem foi conclu√≠da com sucesso e os dados foram salvos para a sua consulta. Obrigado por usar o ClinicAI.'. "
            "O grafo ser√° encerrado ap√≥s esta resposta. O JSON 'triagem_data' deve refletir o estado final do resumo."
        )
        new_resumo_confirmado = True # Marca a flag
    
    # Cria o hist√≥rico de mensagens para enviar ao LLM
    prompt_history = "\n".join([f"{msg.get('sender', 'user')}: {msg.get('text', '')}" for msg in messages])
    
    # Adiciona a instru√ß√£o do sistema e a instru√ß√£o for√ßada, se houver
    full_prompt = SYSTEM_PROMPT + forced_instruction + "\n\nHIST√ìRICO DA CONVERSA:\n" + prompt_history

    # --- IN√çCIO DA √öNICA CHAMADA DE API ---
    response_text = ""
    try:
        response = llm.models.generate_content(
            model=MODEL_NAME, 
            contents=[{"role": "user", "parts": [{"text": full_prompt}]}]
        )
        response_text_raw = clean_json_string(response.text)
        
        # Tenta decodificar o JSON √∫nico
        response_data = json.loads(response_text_raw) 
        
        response_text = response_data.get("next_response", "Desculpe, n√£o consegui gerar a pr√≥xima resposta.")
        triagem = response_data.get("triagem_data", state.get("triagem", {})) 
        
    except Exception as e:
        # Mant√©m a triagem anterior em caso de falha.
        print(f"Erro na √öNICA CHAMADA DE API/Parsing de JSON: {e}. Retorno bruto: {response_text_raw if 'response_text_raw' in locals() else 'N/A'}")
        response_text = "Houve um erro no processamento. Por favor, tente novamente."
        triagem = state.get("triagem", {}) 
    # --- FIM DA √öNICA CHAMADA DE API ---

    # 3. Adiciona a resposta do agente ao hist√≥rico
    messages.append({"id": len(messages) + 1, "text": response_text, "sender": "model"})

    # 4. Atualiza flags (emergency_detected)
    emergency_detected = triagem.get("emergency_alert", False) or state.get("emergency_detected", False)
    
    # Adiciona o contador de turnos
    new_turn_count = state.get("turn_count", 0) + 1

    return {
        "messages": messages,
        "triagem": triagem,
        "resumo_confirmado": new_resumo_confirmado,
        "emergency_detected": emergency_detected,
        "turn_count": new_turn_count 
    }

def emergency_protocol(state: State):
    """
    N√≥ de parada: Envia a mensagem de alerta e for√ßa o fim da triagem.
    """
    alert_message = (
        "üö® **ALERTA DE EMERG√äNCIA** üö®\n\n"
        "Entendi. Seus sintomas podem indicar uma situa√ß√£o de emerg√™ncia. "
        "Por favor, **interrompa esta conversa** e procure o pronto-socorro mais pr√≥ximo ou ligue para o **192** (SAMU) imediatamente."
    )
    
    messages = state["messages"] + [{"id": len(state["messages"]) + 1, "text": alert_message, "sender": "model"}]

    return {
        "messages": messages,
        "emergency_detected": True, 
        "resumo_confirmado": True,
        "turn_count": state.get("turn_count", 0)
    }

def router_emergency(state: State) -> str:
    last_user_message = state["messages"][-1].get("text", "").lower()
    
    if any(kw in last_user_message for kw in EMERGENCY_KEYWORDS):
        return "emergency"
    
    if state.get("emergency_detected"):
        return "emergency"
        
    return "continue_triage"

def router_end(state: State) -> str:
    """Roteia para o n√≥ de salvamento se o resumo for confirmado, ou volta para a triagem.
    Adiciona uma condi√ß√£o de seguran√ßa para o contador de turnos.
    """
    # Condi√ß√£o 1: Confirma√ß√£o do resumo (principal)
    if state.get("resumo_confirmado"):
        return "save_and_end"
    
    # Condi√ß√£o 2 (Seguran√ßa): Limite de turnos alcan√ßado
    if state.get("turn_count", 0) >= 15: 
        print(f"AVISO: LangGraph atingiu o limite de turnos ({state['turn_count']}). For√ßando encerramento.")
        state["resumo_confirmado"] = True 
        return "save_and_end"
        
    return "continue_triage"

# ----------------------------------------------------
# 4. CONFIGURA√á√ÉO DO GRAFO 
# ----------------------------------------------------

graph = StateGraph(State)

graph.add_node("chatbot", chatbot_node)
graph.add_node("emergency_protocol", emergency_protocol)
graph.add_node("end_or_continue", lambda x: x) 

graph.set_entry_point("chatbot")

graph.add_conditional_edges(
    "chatbot",
    router_emergency,
    {
        "emergency": "emergency_protocol",
        "continue_triage": "end_or_continue" # Roteia diretamente para o ponto de roteamento final
    }
)

# Roteia de Emerg√™ncia para o ponto de roteamento final
graph.add_edge("emergency_protocol", "end_or_continue") 

graph.add_conditional_edges(
    "end_or_continue", 
    router_end,
    {
        "save_and_end": END,
        "continue_triage": "chatbot" 
    }
)

app = graph.compile()

# ----------------------------------------------------
# 5. FUN√á√ÉO DE INTEGRA√á√ÉO COM BANCO
# ----------------------------------------------------

def run_agent(chat_id: str, user_message: str) -> str:
    """
    L√≥gica de integra√ß√£o: Carrega estado, executa o grafo, salva o estado atualizado.
    """
    print("\n--- INICIANDO DEPURAC√ÉO DA FUN√á√ÉO run_agent ---")
    
    chat = collection.find_one({"_id": ObjectId(chat_id)})
    if not chat:
        raise ValueError("Chat n√£o encontrado")

    # 1. Prepara o estado inicial
    messages = chat.get("messages", []) + [{"sender": "user", "text": user_message}]
    state = {
        "messages": messages,
        "triagem": chat.get("triagem", {}),
        "resumo_confirmado": chat.get("resumo_confirmado", False),
        "emergency_detected": chat.get("emergency_detected", False),
        "turn_count": chat.get("turn_count", 0) 
    }
    
    print(f"1. ESTADO INICIAL (carregado do DB): {state}")

    # 2. Executa o LangGraph usando stream para rodar um turno
    final_state = state.copy()
    
    for s in app.stream(state):
        print(f"2. ATUALIZA√á√ÉO DO GRAFO (Stream): {s}")
        final_state.update(s)
        
        # Condi√ß√£o de parada de turno 
        if "__end__" in s or "decision_point" in s or "emergency_protocol" in s:
            print("2.1. O LangGraph atingiu um n√≥ de parada. Saindo do loop de stream.")
            break
            
    updated_state = final_state
    
    print(f"3. ESTADO FINAL ATUALIZADO (ap√≥s o stream): {updated_state}")
    
    # 3. Prepara a atualiza√ß√£o base para o DB 
    update_fields = {
        "messages": updated_state.get("messages", []),
        "triagem": updated_state.get("triagem", {}),
        "resumo_confirmado": updated_state.get("resumo_confirmado", False),
        "emergency_detected": updated_state.get("emergency_detected", False),
        "turn_count": updated_state.get("turn_count", 0),
        "is_completed": False
    }

    print(f"4. VALOR DA FLAG 'resumo_confirmado': {updated_state.get('resumo_confirmado')}")
    
    # 4. L√ìGICA DE SALVAMENTO FINAL E CONCLUS√ÉO 
    if updated_state.get("resumo_confirmado"):
        print("5. DETECTADO: resumo_confirmado √© True. Entrando na l√≥gica de salvamento final.")
        
        update_fields["is_completed"] = True
        update_fields["triagem"] = updated_state.get("triagem", {}) 
        
        if updated_state.get("emergency_detected"):
            update_fields["status"] = "EMERGENCY_ALERT"
        else:
            update_fields["status"] = "TRIAGE_COMPLETED"
    else:
        print("5. DETECTADO: resumo_confirmado √© False. Nenhuma a√ß√£o de salvamento final.")

    print(f"6. CAMPOS PREPARADOS PARA O DB: {update_fields}")

    # 5. Atualiza o MongoDB.
    collection.update_one(
        {"_id": ObjectId(chat_id)},
        {"$set": update_fields}
    )

    # 6. Retorna a √∫ltima mensagem do agente
    agent_response = updated_state["messages"][-1]["text"]
    print(f"7. RESPOSTA DO AGENTE RETORNADA: {agent_response}")
    print("\n--- FIM DA DEPURAC√ÉO ---")

    return agent_response